{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f088e7ca-ee25-431a-8159-1597dc4342a5",
   "metadata": {},
   "source": [
    "# import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db5a202c-e390-4663-b8d5-8fe40c8409c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66daf042-b43d-448d-b1ff-1f957cb66c94",
   "metadata": {},
   "source": [
    "# Download the dataset from the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd0bfa53-6fe5-4801-a76d-0573b3710902",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3d55979-9d78-4b7f-a5fa-171b9ab59d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1a5aa4e-65ed-442b-879b-f868d8bc4da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "231d0d5d-818e-4075-b4e1-0c68f1a60242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3ab456-4bbd-4903-99ff-9a4514178555",
   "metadata": {},
   "source": [
    "# .shape is same as .size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6b670de-b8f4-433b-83d8-0b4867ddd6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4939006-2b86-45a1-aee8-f62f8e03a52d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45a36e8-a687-43a4-9b9c-96bc314904ae",
   "metadata": {},
   "source": [
    "# Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e75a90b7-2e6a-4557-89ce-1097ccc7ec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "    'train' : DataLoader(train_data,\n",
    "                         batch_size=100,\n",
    "                         shuffle=True,\n",
    "                         num_workers=1),\n",
    "    'test' : DataLoader(test_data,\n",
    "                        batch_size=100,\n",
    "                        shuffle=True,\n",
    "                        num_workers=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c492289d-54b4-494d-b8fa-458b28af509c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x7cda135506e0>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x7cda13528690>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbeeb759-97d1-43c1-8e97-4a50ba5e507c",
   "metadata": {},
   "source": [
    "# Create our neural network\n",
    "\n",
    "`self.conv1 = nn.Conv2d(1, 10, kernel_size=5)`\n",
    "\n",
    "is defining a convolutional layer in a PyTorch neural network. Specifically:\n",
    "\n",
    "nn.Conv2d is a 2D convolutional layer used primarily for processing image data.\n",
    "\n",
    "The first argument 1 is the number of input channels. For example, if the input is a grayscale image, it has 1 channel.\n",
    "\n",
    "The second argument 10 is the number of output channels, meaning this layer will learn 10 different filters (or feature detectors).\n",
    "\n",
    "kernel_size=5 means each filter is a 5x5 square that will slide over the input image to detect features.\n",
    "\n",
    "`self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320,50)\n",
    "        self.fc2 = nn.Linear(50,10)\n",
    "        `\n",
    "        \n",
    "self.conv2_drop = nn.Dropout2d()\n",
    "This creates a 2D dropout layer, which randomly zeroes entire channels in the feature map during training to reduce overfitting.\n",
    "\n",
    "self.fc1 = nn.Linear(320, 50)\n",
    "This defines a fully connected (linear) layer with 320 input features and 50 output features (neurons).\n",
    "\n",
    "self.fc2 = nn.Linear(50, 10)\n",
    "This defines another fully connected layer taking the 50 features from the previous layer as input and outputting 10 features, often used as class scores for a 10-class classification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5cfccab-3674-44a1-bb6c-83c740ac2dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320,50)\n",
    "        self.fc2 = nn.Linear(50,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)),2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.softmax(x)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8021558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders['train'].dataset)} ({100. * batch_idx / len(loaders['train']):.0f}%)]\\t{loss.item():.6f}\")\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders[\"test\"]:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(loaders['test'].dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy {correct}/{len(loaders[\"test\"].dataset)} ({100. * correct / len(loaders[\"test\"].dataset):.0f}%)\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06be9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10940/3581625747.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\t2.301714\n",
      "Train Epoch: 1 [2000/60000 (3%)]\t2.276603\n",
      "Train Epoch: 1 [4000/60000 (7%)]\t2.126235\n",
      "Train Epoch: 1 [6000/60000 (10%)]\t1.868685\n",
      "Train Epoch: 1 [8000/60000 (13%)]\t1.859537\n",
      "Train Epoch: 1 [10000/60000 (17%)]\t1.760194\n",
      "Train Epoch: 1 [12000/60000 (20%)]\t1.804528\n",
      "Train Epoch: 1 [14000/60000 (23%)]\t1.715340\n",
      "Train Epoch: 1 [16000/60000 (27%)]\t1.696078\n",
      "Train Epoch: 1 [18000/60000 (30%)]\t1.705026\n",
      "Train Epoch: 1 [20000/60000 (33%)]\t1.706696\n",
      "Train Epoch: 1 [22000/60000 (37%)]\t1.699240\n",
      "Train Epoch: 1 [24000/60000 (40%)]\t1.778364\n",
      "Train Epoch: 1 [26000/60000 (43%)]\t1.663630\n",
      "Train Epoch: 1 [28000/60000 (47%)]\t1.649062\n",
      "Train Epoch: 1 [30000/60000 (50%)]\t1.647227\n",
      "Train Epoch: 1 [32000/60000 (53%)]\t1.653231\n",
      "Train Epoch: 1 [34000/60000 (57%)]\t1.653567\n",
      "Train Epoch: 1 [36000/60000 (60%)]\t1.629438\n",
      "Train Epoch: 1 [38000/60000 (63%)]\t1.606007\n",
      "Train Epoch: 1 [40000/60000 (67%)]\t1.648028\n",
      "Train Epoch: 1 [42000/60000 (70%)]\t1.592512\n",
      "Train Epoch: 1 [44000/60000 (73%)]\t1.610797\n",
      "Train Epoch: 1 [46000/60000 (77%)]\t1.613668\n",
      "Train Epoch: 1 [48000/60000 (80%)]\t1.689585\n",
      "Train Epoch: 1 [50000/60000 (83%)]\t1.601286\n",
      "Train Epoch: 1 [52000/60000 (87%)]\t1.629677\n",
      "Train Epoch: 1 [54000/60000 (90%)]\t1.584457\n",
      "Train Epoch: 1 [56000/60000 (93%)]\t1.615795\n",
      "Train Epoch: 1 [58000/60000 (97%)]\t1.611977\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy 9379/10000 (94%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\t1.587514\n",
      "Train Epoch: 2 [2000/60000 (3%)]\t1.610095\n",
      "Train Epoch: 2 [4000/60000 (7%)]\t1.588107\n",
      "Train Epoch: 2 [6000/60000 (10%)]\t1.550215\n",
      "Train Epoch: 2 [8000/60000 (13%)]\t1.608594\n",
      "Train Epoch: 2 [10000/60000 (17%)]\t1.557045\n",
      "Train Epoch: 2 [12000/60000 (20%)]\t1.569154\n",
      "Train Epoch: 2 [14000/60000 (23%)]\t1.556529\n",
      "Train Epoch: 2 [16000/60000 (27%)]\t1.587413\n",
      "Train Epoch: 2 [18000/60000 (30%)]\t1.605672\n",
      "Train Epoch: 2 [20000/60000 (33%)]\t1.570815\n",
      "Train Epoch: 2 [22000/60000 (37%)]\t1.603471\n",
      "Train Epoch: 2 [24000/60000 (40%)]\t1.558632\n",
      "Train Epoch: 2 [26000/60000 (43%)]\t1.560895\n",
      "Train Epoch: 2 [28000/60000 (47%)]\t1.656547\n",
      "Train Epoch: 2 [30000/60000 (50%)]\t1.591865\n",
      "Train Epoch: 2 [32000/60000 (53%)]\t1.611175\n",
      "Train Epoch: 2 [34000/60000 (57%)]\t1.547517\n",
      "Train Epoch: 2 [36000/60000 (60%)]\t1.578893\n",
      "Train Epoch: 2 [38000/60000 (63%)]\t1.558585\n",
      "Train Epoch: 2 [40000/60000 (67%)]\t1.572008\n",
      "Train Epoch: 2 [42000/60000 (70%)]\t1.559252\n",
      "Train Epoch: 2 [44000/60000 (73%)]\t1.552314\n",
      "Train Epoch: 2 [46000/60000 (77%)]\t1.593449\n",
      "Train Epoch: 2 [48000/60000 (80%)]\t1.545287\n",
      "Train Epoch: 2 [50000/60000 (83%)]\t1.559338\n",
      "Train Epoch: 2 [52000/60000 (87%)]\t1.625718\n",
      "Train Epoch: 2 [54000/60000 (90%)]\t1.574150\n",
      "Train Epoch: 2 [56000/60000 (93%)]\t1.561160\n",
      "Train Epoch: 2 [58000/60000 (97%)]\t1.568752\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy 9540/10000 (95%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\t1.567888\n",
      "Train Epoch: 3 [2000/60000 (3%)]\t1.558442\n",
      "Train Epoch: 3 [4000/60000 (7%)]\t1.570799\n",
      "Train Epoch: 3 [6000/60000 (10%)]\t1.540358\n",
      "Train Epoch: 3 [8000/60000 (13%)]\t1.573817\n",
      "Train Epoch: 3 [10000/60000 (17%)]\t1.541332\n",
      "Train Epoch: 3 [12000/60000 (20%)]\t1.580921\n",
      "Train Epoch: 3 [14000/60000 (23%)]\t1.578482\n",
      "Train Epoch: 3 [16000/60000 (27%)]\t1.565185\n",
      "Train Epoch: 3 [18000/60000 (30%)]\t1.546066\n",
      "Train Epoch: 3 [20000/60000 (33%)]\t1.519586\n",
      "Train Epoch: 3 [22000/60000 (37%)]\t1.526689\n",
      "Train Epoch: 3 [24000/60000 (40%)]\t1.592896\n",
      "Train Epoch: 3 [26000/60000 (43%)]\t1.547793\n",
      "Train Epoch: 3 [28000/60000 (47%)]\t1.546045\n",
      "Train Epoch: 3 [30000/60000 (50%)]\t1.548850\n",
      "Train Epoch: 3 [32000/60000 (53%)]\t1.521603\n",
      "Train Epoch: 3 [34000/60000 (57%)]\t1.513252\n",
      "Train Epoch: 3 [36000/60000 (60%)]\t1.590673\n",
      "Train Epoch: 3 [38000/60000 (63%)]\t1.531322\n",
      "Train Epoch: 3 [40000/60000 (67%)]\t1.555713\n",
      "Train Epoch: 3 [42000/60000 (70%)]\t1.588032\n",
      "Train Epoch: 3 [44000/60000 (73%)]\t1.526773\n",
      "Train Epoch: 3 [46000/60000 (77%)]\t1.606237\n",
      "Train Epoch: 3 [48000/60000 (80%)]\t1.530477\n",
      "Train Epoch: 3 [50000/60000 (83%)]\t1.566044\n",
      "Train Epoch: 3 [52000/60000 (87%)]\t1.549768\n",
      "Train Epoch: 3 [54000/60000 (90%)]\t1.524796\n",
      "Train Epoch: 3 [56000/60000 (93%)]\t1.580244\n",
      "Train Epoch: 3 [58000/60000 (97%)]\t1.553007\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy 9631/10000 (96%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\t1.582750\n",
      "Train Epoch: 4 [2000/60000 (3%)]\t1.507627\n",
      "Train Epoch: 4 [4000/60000 (7%)]\t1.512970\n",
      "Train Epoch: 4 [6000/60000 (10%)]\t1.536139\n",
      "Train Epoch: 4 [8000/60000 (13%)]\t1.526797\n",
      "Train Epoch: 4 [10000/60000 (17%)]\t1.592218\n",
      "Train Epoch: 4 [12000/60000 (20%)]\t1.552013\n",
      "Train Epoch: 4 [14000/60000 (23%)]\t1.530946\n",
      "Train Epoch: 4 [16000/60000 (27%)]\t1.540253\n",
      "Train Epoch: 4 [18000/60000 (30%)]\t1.552740\n",
      "Train Epoch: 4 [20000/60000 (33%)]\t1.543105\n",
      "Train Epoch: 4 [22000/60000 (37%)]\t1.628389\n",
      "Train Epoch: 4 [24000/60000 (40%)]\t1.507003\n",
      "Train Epoch: 4 [26000/60000 (43%)]\t1.587358\n",
      "Train Epoch: 4 [28000/60000 (47%)]\t1.548780\n",
      "Train Epoch: 4 [30000/60000 (50%)]\t1.564236\n",
      "Train Epoch: 4 [32000/60000 (53%)]\t1.572085\n",
      "Train Epoch: 4 [34000/60000 (57%)]\t1.562659\n",
      "Train Epoch: 4 [36000/60000 (60%)]\t1.549474\n",
      "Train Epoch: 4 [38000/60000 (63%)]\t1.567657\n",
      "Train Epoch: 4 [40000/60000 (67%)]\t1.531448\n",
      "Train Epoch: 4 [42000/60000 (70%)]\t1.541795\n",
      "Train Epoch: 4 [44000/60000 (73%)]\t1.546098\n",
      "Train Epoch: 4 [46000/60000 (77%)]\t1.558667\n",
      "Train Epoch: 4 [48000/60000 (80%)]\t1.527917\n",
      "Train Epoch: 4 [50000/60000 (83%)]\t1.494241\n",
      "Train Epoch: 4 [52000/60000 (87%)]\t1.515990\n",
      "Train Epoch: 4 [54000/60000 (90%)]\t1.559657\n",
      "Train Epoch: 4 [56000/60000 (93%)]\t1.546139\n",
      "Train Epoch: 4 [58000/60000 (97%)]\t1.556461\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy 9659/10000 (97%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\t1.536595\n",
      "Train Epoch: 5 [2000/60000 (3%)]\t1.531895\n",
      "Train Epoch: 5 [4000/60000 (7%)]\t1.507735\n",
      "Train Epoch: 5 [6000/60000 (10%)]\t1.499052\n",
      "Train Epoch: 5 [8000/60000 (13%)]\t1.502742\n",
      "Train Epoch: 5 [10000/60000 (17%)]\t1.526129\n",
      "Train Epoch: 5 [12000/60000 (20%)]\t1.556921\n",
      "Train Epoch: 5 [14000/60000 (23%)]\t1.535196\n",
      "Train Epoch: 5 [16000/60000 (27%)]\t1.485263\n",
      "Train Epoch: 5 [18000/60000 (30%)]\t1.552329\n",
      "Train Epoch: 5 [20000/60000 (33%)]\t1.542768\n",
      "Train Epoch: 5 [22000/60000 (37%)]\t1.517752\n",
      "Train Epoch: 5 [24000/60000 (40%)]\t1.548649\n",
      "Train Epoch: 5 [26000/60000 (43%)]\t1.533258\n",
      "Train Epoch: 5 [28000/60000 (47%)]\t1.542532\n",
      "Train Epoch: 5 [30000/60000 (50%)]\t1.551700\n",
      "Train Epoch: 5 [32000/60000 (53%)]\t1.532691\n",
      "Train Epoch: 5 [34000/60000 (57%)]\t1.522129\n",
      "Train Epoch: 5 [36000/60000 (60%)]\t1.518582\n",
      "Train Epoch: 5 [38000/60000 (63%)]\t1.521116\n",
      "Train Epoch: 5 [40000/60000 (67%)]\t1.520805\n",
      "Train Epoch: 5 [42000/60000 (70%)]\t1.527162\n",
      "Train Epoch: 5 [44000/60000 (73%)]\t1.521269\n",
      "Train Epoch: 5 [46000/60000 (77%)]\t1.496993\n",
      "Train Epoch: 5 [48000/60000 (80%)]\t1.517693\n",
      "Train Epoch: 5 [50000/60000 (83%)]\t1.538496\n",
      "Train Epoch: 5 [52000/60000 (87%)]\t1.492208\n",
      "Train Epoch: 5 [54000/60000 (90%)]\t1.549687\n",
      "Train Epoch: 5 [56000/60000 (93%)]\t1.554130\n",
      "Train Epoch: 5 [58000/60000 (97%)]\t1.554015\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy 9652/10000 (97%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\t1.521051\n",
      "Train Epoch: 6 [2000/60000 (3%)]\t1.533312\n",
      "Train Epoch: 6 [4000/60000 (7%)]\t1.531460\n",
      "Train Epoch: 6 [6000/60000 (10%)]\t1.573305\n",
      "Train Epoch: 6 [8000/60000 (13%)]\t1.492366\n",
      "Train Epoch: 6 [10000/60000 (17%)]\t1.553418\n",
      "Train Epoch: 6 [12000/60000 (20%)]\t1.521553\n",
      "Train Epoch: 6 [14000/60000 (23%)]\t1.552538\n",
      "Train Epoch: 6 [16000/60000 (27%)]\t1.524347\n",
      "Train Epoch: 6 [18000/60000 (30%)]\t1.544758\n",
      "Train Epoch: 6 [20000/60000 (33%)]\t1.532165\n",
      "Train Epoch: 6 [22000/60000 (37%)]\t1.555833\n",
      "Train Epoch: 6 [24000/60000 (40%)]\t1.512314\n",
      "Train Epoch: 6 [26000/60000 (43%)]\t1.559521\n",
      "Train Epoch: 6 [28000/60000 (47%)]\t1.490387\n",
      "Train Epoch: 6 [30000/60000 (50%)]\t1.508124\n",
      "Train Epoch: 6 [32000/60000 (53%)]\t1.517291\n",
      "Train Epoch: 6 [34000/60000 (57%)]\t1.548632\n",
      "Train Epoch: 6 [36000/60000 (60%)]\t1.499827\n",
      "Train Epoch: 6 [38000/60000 (63%)]\t1.555096\n",
      "Train Epoch: 6 [40000/60000 (67%)]\t1.564580\n",
      "Train Epoch: 6 [42000/60000 (70%)]\t1.523190\n",
      "Train Epoch: 6 [44000/60000 (73%)]\t1.595630\n",
      "Train Epoch: 6 [46000/60000 (77%)]\t1.506767\n",
      "Train Epoch: 6 [48000/60000 (80%)]\t1.521391\n",
      "Train Epoch: 6 [50000/60000 (83%)]\t1.519256\n",
      "Train Epoch: 6 [52000/60000 (87%)]\t1.543209\n",
      "Train Epoch: 6 [54000/60000 (90%)]\t1.607684\n",
      "Train Epoch: 6 [56000/60000 (93%)]\t1.546553\n",
      "Train Epoch: 6 [58000/60000 (97%)]\t1.495337\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9710/10000 (97%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\t1.512923\n",
      "Train Epoch: 7 [2000/60000 (3%)]\t1.539749\n",
      "Train Epoch: 7 [4000/60000 (7%)]\t1.513080\n",
      "Train Epoch: 7 [6000/60000 (10%)]\t1.490238\n",
      "Train Epoch: 7 [8000/60000 (13%)]\t1.505696\n",
      "Train Epoch: 7 [10000/60000 (17%)]\t1.532694\n",
      "Train Epoch: 7 [12000/60000 (20%)]\t1.535399\n",
      "Train Epoch: 7 [14000/60000 (23%)]\t1.580427\n",
      "Train Epoch: 7 [16000/60000 (27%)]\t1.522481\n",
      "Train Epoch: 7 [18000/60000 (30%)]\t1.498633\n",
      "Train Epoch: 7 [20000/60000 (33%)]\t1.535310\n",
      "Train Epoch: 7 [22000/60000 (37%)]\t1.515478\n",
      "Train Epoch: 7 [24000/60000 (40%)]\t1.569278\n",
      "Train Epoch: 7 [26000/60000 (43%)]\t1.546894\n",
      "Train Epoch: 7 [28000/60000 (47%)]\t1.540744\n",
      "Train Epoch: 7 [30000/60000 (50%)]\t1.528975\n",
      "Train Epoch: 7 [32000/60000 (53%)]\t1.506613\n",
      "Train Epoch: 7 [34000/60000 (57%)]\t1.524407\n",
      "Train Epoch: 7 [36000/60000 (60%)]\t1.512908\n",
      "Train Epoch: 7 [38000/60000 (63%)]\t1.517566\n",
      "Train Epoch: 7 [40000/60000 (67%)]\t1.538945\n",
      "Train Epoch: 7 [42000/60000 (70%)]\t1.539953\n",
      "Train Epoch: 7 [44000/60000 (73%)]\t1.517548\n",
      "Train Epoch: 7 [46000/60000 (77%)]\t1.495378\n",
      "Train Epoch: 7 [48000/60000 (80%)]\t1.508371\n",
      "Train Epoch: 7 [50000/60000 (83%)]\t1.500912\n",
      "Train Epoch: 7 [52000/60000 (87%)]\t1.505894\n",
      "Train Epoch: 7 [54000/60000 (90%)]\t1.527230\n",
      "Train Epoch: 7 [56000/60000 (93%)]\t1.516323\n",
      "Train Epoch: 7 [58000/60000 (97%)]\t1.545485\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9729/10000 (97%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\t1.513106\n",
      "Train Epoch: 8 [2000/60000 (3%)]\t1.508919\n",
      "Train Epoch: 8 [4000/60000 (7%)]\t1.500614\n",
      "Train Epoch: 8 [6000/60000 (10%)]\t1.558334\n",
      "Train Epoch: 8 [8000/60000 (13%)]\t1.530361\n",
      "Train Epoch: 8 [10000/60000 (17%)]\t1.498450\n",
      "Train Epoch: 8 [12000/60000 (20%)]\t1.516133\n",
      "Train Epoch: 8 [14000/60000 (23%)]\t1.562460\n",
      "Train Epoch: 8 [16000/60000 (27%)]\t1.530238\n",
      "Train Epoch: 8 [18000/60000 (30%)]\t1.511932\n",
      "Train Epoch: 8 [20000/60000 (33%)]\t1.558213\n",
      "Train Epoch: 8 [22000/60000 (37%)]\t1.560936\n",
      "Train Epoch: 8 [24000/60000 (40%)]\t1.572293\n",
      "Train Epoch: 8 [26000/60000 (43%)]\t1.543013\n",
      "Train Epoch: 8 [28000/60000 (47%)]\t1.517797\n",
      "Train Epoch: 8 [30000/60000 (50%)]\t1.520962\n",
      "Train Epoch: 8 [32000/60000 (53%)]\t1.515214\n",
      "Train Epoch: 8 [34000/60000 (57%)]\t1.503575\n",
      "Train Epoch: 8 [36000/60000 (60%)]\t1.525035\n",
      "Train Epoch: 8 [38000/60000 (63%)]\t1.497288\n",
      "Train Epoch: 8 [40000/60000 (67%)]\t1.522095\n",
      "Train Epoch: 8 [42000/60000 (70%)]\t1.525738\n",
      "Train Epoch: 8 [44000/60000 (73%)]\t1.498524\n",
      "Train Epoch: 8 [46000/60000 (77%)]\t1.567680\n",
      "Train Epoch: 8 [48000/60000 (80%)]\t1.518593\n",
      "Train Epoch: 8 [50000/60000 (83%)]\t1.561494\n",
      "Train Epoch: 8 [52000/60000 (87%)]\t1.512797\n",
      "Train Epoch: 8 [54000/60000 (90%)]\t1.547362\n",
      "Train Epoch: 8 [56000/60000 (93%)]\t1.548037\n",
      "Train Epoch: 8 [58000/60000 (97%)]\t1.542211\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9721/10000 (97%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\t1.535993\n",
      "Train Epoch: 9 [2000/60000 (3%)]\t1.504285\n",
      "Train Epoch: 9 [4000/60000 (7%)]\t1.554754\n",
      "Train Epoch: 9 [6000/60000 (10%)]\t1.552938\n",
      "Train Epoch: 9 [8000/60000 (13%)]\t1.584444\n",
      "Train Epoch: 9 [10000/60000 (17%)]\t1.540909\n",
      "Train Epoch: 9 [12000/60000 (20%)]\t1.520013\n",
      "Train Epoch: 9 [14000/60000 (23%)]\t1.523645\n",
      "Train Epoch: 9 [16000/60000 (27%)]\t1.537784\n",
      "Train Epoch: 9 [18000/60000 (30%)]\t1.544280\n",
      "Train Epoch: 9 [20000/60000 (33%)]\t1.541511\n",
      "Train Epoch: 9 [22000/60000 (37%)]\t1.491667\n",
      "Train Epoch: 9 [24000/60000 (40%)]\t1.535663\n",
      "Train Epoch: 9 [26000/60000 (43%)]\t1.499973\n",
      "Train Epoch: 9 [28000/60000 (47%)]\t1.519672\n",
      "Train Epoch: 9 [30000/60000 (50%)]\t1.522437\n",
      "Train Epoch: 9 [32000/60000 (53%)]\t1.551860\n",
      "Train Epoch: 9 [34000/60000 (57%)]\t1.494810\n",
      "Train Epoch: 9 [36000/60000 (60%)]\t1.503204\n",
      "Train Epoch: 9 [38000/60000 (63%)]\t1.503897\n",
      "Train Epoch: 9 [40000/60000 (67%)]\t1.515543\n",
      "Train Epoch: 9 [42000/60000 (70%)]\t1.532139\n",
      "Train Epoch: 9 [44000/60000 (73%)]\t1.520838\n",
      "Train Epoch: 9 [46000/60000 (77%)]\t1.508088\n",
      "Train Epoch: 9 [48000/60000 (80%)]\t1.513987\n",
      "Train Epoch: 9 [50000/60000 (83%)]\t1.550997\n",
      "Train Epoch: 9 [52000/60000 (87%)]\t1.551830\n",
      "Train Epoch: 9 [54000/60000 (90%)]\t1.523370\n",
      "Train Epoch: 9 [56000/60000 (93%)]\t1.487129\n",
      "Train Epoch: 9 [58000/60000 (97%)]\t1.495039\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9716/10000 (97%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\t1.535793\n",
      "Train Epoch: 10 [2000/60000 (3%)]\t1.526144\n",
      "Train Epoch: 10 [4000/60000 (7%)]\t1.500188\n",
      "Train Epoch: 10 [6000/60000 (10%)]\t1.545714\n",
      "Train Epoch: 10 [8000/60000 (13%)]\t1.519885\n",
      "Train Epoch: 10 [10000/60000 (17%)]\t1.538719\n",
      "Train Epoch: 10 [12000/60000 (20%)]\t1.488161\n",
      "Train Epoch: 10 [14000/60000 (23%)]\t1.530408\n",
      "Train Epoch: 10 [16000/60000 (27%)]\t1.545201\n",
      "Train Epoch: 10 [18000/60000 (30%)]\t1.540717\n",
      "Train Epoch: 10 [20000/60000 (33%)]\t1.513097\n",
      "Train Epoch: 10 [22000/60000 (37%)]\t1.536127\n",
      "Train Epoch: 10 [24000/60000 (40%)]\t1.511002\n",
      "Train Epoch: 10 [26000/60000 (43%)]\t1.518053\n",
      "Train Epoch: 10 [28000/60000 (47%)]\t1.514904\n",
      "Train Epoch: 10 [30000/60000 (50%)]\t1.511425\n",
      "Train Epoch: 10 [32000/60000 (53%)]\t1.522324\n",
      "Train Epoch: 10 [34000/60000 (57%)]\t1.543686\n",
      "Train Epoch: 10 [36000/60000 (60%)]\t1.532422\n",
      "Train Epoch: 10 [38000/60000 (63%)]\t1.494100\n",
      "Train Epoch: 10 [40000/60000 (67%)]\t1.551801\n",
      "Train Epoch: 10 [42000/60000 (70%)]\t1.554719\n",
      "Train Epoch: 10 [44000/60000 (73%)]\t1.532324\n",
      "Train Epoch: 10 [46000/60000 (77%)]\t1.510139\n",
      "Train Epoch: 10 [48000/60000 (80%)]\t1.527472\n",
      "Train Epoch: 10 [50000/60000 (83%)]\t1.497827\n",
      "Train Epoch: 10 [52000/60000 (87%)]\t1.524686\n",
      "Train Epoch: 10 [54000/60000 (90%)]\t1.514747\n",
      "Train Epoch: 10 [56000/60000 (93%)]\t1.534878\n",
      "Train Epoch: 10 [58000/60000 (97%)]\t1.508566\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9752/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,11):\n",
    "    train(epoch)\n",
    "    test() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99c8ddb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b934ebbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10940/3581625747.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "\n",
    "data, target = test_data[7]\n",
    "\n",
    "data = data.unsqueeze(0).to(device)\n",
    "\n",
    "output = model(data)\n",
    "\n",
    "prediction = output.argmax(dim=1, keepdim=True).item()\n",
    "\n",
    "print(f'Prediction: {prediction}')\n",
    "\n",
    "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
